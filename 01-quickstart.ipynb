{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29654d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3729f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e9d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40758fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c264d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adffd680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb05e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06bb9861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.140722  [   64/60000]\n",
      "loss: 1.149707  [ 6464/60000]\n",
      "loss: 0.961307  [12864/60000]\n",
      "loss: 1.105002  [19264/60000]\n",
      "loss: 0.982036  [25664/60000]\n",
      "loss: 1.009380  [32064/60000]\n",
      "loss: 1.060854  [38464/60000]\n",
      "loss: 0.985263  [44864/60000]\n",
      "loss: 1.032493  [51264/60000]\n",
      "loss: 0.952699  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.972713 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.027146  [   64/60000]\n",
      "loss: 1.057079  [ 6464/60000]\n",
      "loss: 0.849847  [12864/60000]\n",
      "loss: 1.015722  [19264/60000]\n",
      "loss: 0.896640  [25664/60000]\n",
      "loss: 0.919335  [32064/60000]\n",
      "loss: 0.987093  [38464/60000]\n",
      "loss: 0.912945  [44864/60000]\n",
      "loss: 0.956910  [51264/60000]\n",
      "loss: 0.888194  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.902451 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.942487  [   64/60000]\n",
      "loss: 0.991508  [ 6464/60000]\n",
      "loss: 0.769015  [12864/60000]\n",
      "loss: 0.951926  [19264/60000]\n",
      "loss: 0.839234  [25664/60000]\n",
      "loss: 0.853250  [32064/60000]\n",
      "loss: 0.934614  [38464/60000]\n",
      "loss: 0.864034  [44864/60000]\n",
      "loss: 0.901848  [51264/60000]\n",
      "loss: 0.841676  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.851553 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.876952  [   64/60000]\n",
      "loss: 0.941925  [ 6464/60000]\n",
      "loss: 0.708244  [12864/60000]\n",
      "loss: 0.904433  [19264/60000]\n",
      "loss: 0.798371  [25664/60000]\n",
      "loss: 0.803528  [32064/60000]\n",
      "loss: 0.894598  [38464/60000]\n",
      "loss: 0.829791  [44864/60000]\n",
      "loss: 0.860353  [51264/60000]\n",
      "loss: 0.806088  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.812838 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.824341  [   64/60000]\n",
      "loss: 0.902008  [ 6464/60000]\n",
      "loss: 0.660964  [12864/60000]\n",
      "loss: 0.867928  [19264/60000]\n",
      "loss: 0.767363  [25664/60000]\n",
      "loss: 0.765171  [32064/60000]\n",
      "loss: 0.862042  [38464/60000]\n",
      "loss: 0.804570  [44864/60000]\n",
      "loss: 0.827968  [51264/60000]\n",
      "loss: 0.777567  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.781967 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.780686  [   64/60000]\n",
      "loss: 0.868102  [ 6464/60000]\n",
      "loss: 0.622777  [12864/60000]\n",
      "loss: 0.839084  [19264/60000]\n",
      "loss: 0.742510  [25664/60000]\n",
      "loss: 0.734979  [32064/60000]\n",
      "loss: 0.834129  [38464/60000]\n",
      "loss: 0.784954  [44864/60000]\n",
      "loss: 0.801757  [51264/60000]\n",
      "loss: 0.753533  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.756236 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.743500  [   64/60000]\n",
      "loss: 0.838238  [ 6464/60000]\n",
      "loss: 0.590991  [12864/60000]\n",
      "loss: 0.815643  [19264/60000]\n",
      "loss: 0.721672  [25664/60000]\n",
      "loss: 0.710789  [32064/60000]\n",
      "loss: 0.809065  [38464/60000]\n",
      "loss: 0.768695  [44864/60000]\n",
      "loss: 0.779866  [51264/60000]\n",
      "loss: 0.732638  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.733990 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.711240  [   64/60000]\n",
      "loss: 0.811287  [ 6464/60000]\n",
      "loss: 0.564107  [12864/60000]\n",
      "loss: 0.795788  [19264/60000]\n",
      "loss: 0.703577  [25664/60000]\n",
      "loss: 0.690957  [32064/60000]\n",
      "loss: 0.786052  [38464/60000]\n",
      "loss: 0.754730  [44864/60000]\n",
      "loss: 0.760970  [51264/60000]\n",
      "loss: 0.714113  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.714325 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.682805  [   64/60000]\n",
      "loss: 0.786633  [ 6464/60000]\n",
      "loss: 0.540848  [12864/60000]\n",
      "loss: 0.778673  [19264/60000]\n",
      "loss: 0.687504  [25664/60000]\n",
      "loss: 0.674317  [32064/60000]\n",
      "loss: 0.764742  [38464/60000]\n",
      "loss: 0.742300  [44864/60000]\n",
      "loss: 0.744491  [51264/60000]\n",
      "loss: 0.697369  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.696611 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.657529  [   64/60000]\n",
      "loss: 0.763942  [ 6464/60000]\n",
      "loss: 0.520504  [12864/60000]\n",
      "loss: 0.763559  [19264/60000]\n",
      "loss: 0.673091  [25664/60000]\n",
      "loss: 0.660165  [32064/60000]\n",
      "loss: 0.744789  [38464/60000]\n",
      "loss: 0.731087  [44864/60000]\n",
      "loss: 0.729980  [51264/60000]\n",
      "loss: 0.682053  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.680473 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.634991  [   64/60000]\n",
      "loss: 0.743029  [ 6464/60000]\n",
      "loss: 0.502546  [12864/60000]\n",
      "loss: 0.749990  [19264/60000]\n",
      "loss: 0.660106  [25664/60000]\n",
      "loss: 0.647915  [32064/60000]\n",
      "loss: 0.726194  [38464/60000]\n",
      "loss: 0.720960  [44864/60000]\n",
      "loss: 0.717168  [51264/60000]\n",
      "loss: 0.667874  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.665691 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.614778  [   64/60000]\n",
      "loss: 0.723899  [ 6464/60000]\n",
      "loss: 0.486553  [12864/60000]\n",
      "loss: 0.737603  [19264/60000]\n",
      "loss: 0.648452  [25664/60000]\n",
      "loss: 0.637227  [32064/60000]\n",
      "loss: 0.708843  [38464/60000]\n",
      "loss: 0.711978  [44864/60000]\n",
      "loss: 0.705916  [51264/60000]\n",
      "loss: 0.654719  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.652109 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.596641  [   64/60000]\n",
      "loss: 0.706256  [ 6464/60000]\n",
      "loss: 0.472222  [12864/60000]\n",
      "loss: 0.726235  [19264/60000]\n",
      "loss: 0.638015  [25664/60000]\n",
      "loss: 0.627827  [32064/60000]\n",
      "loss: 0.692615  [38464/60000]\n",
      "loss: 0.704077  [44864/60000]\n",
      "loss: 0.696072  [51264/60000]\n",
      "loss: 0.642380  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.639600 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.580258  [   64/60000]\n",
      "loss: 0.689943  [ 6464/60000]\n",
      "loss: 0.459286  [12864/60000]\n",
      "loss: 0.715722  [19264/60000]\n",
      "loss: 0.628679  [25664/60000]\n",
      "loss: 0.619505  [32064/60000]\n",
      "loss: 0.677483  [38464/60000]\n",
      "loss: 0.697199  [44864/60000]\n",
      "loss: 0.687619  [51264/60000]\n",
      "loss: 0.630729  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.628085 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.565399  [   64/60000]\n",
      "loss: 0.674920  [ 6464/60000]\n",
      "loss: 0.447562  [12864/60000]\n",
      "loss: 0.705978  [19264/60000]\n",
      "loss: 0.620289  [25664/60000]\n",
      "loss: 0.612028  [32064/60000]\n",
      "loss: 0.663438  [38464/60000]\n",
      "loss: 0.691325  [44864/60000]\n",
      "loss: 0.680369  [51264/60000]\n",
      "loss: 0.619743  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.617521 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.551862  [   64/60000]\n",
      "loss: 0.661198  [ 6464/60000]\n",
      "loss: 0.436901  [12864/60000]\n",
      "loss: 0.696805  [19264/60000]\n",
      "loss: 0.612507  [25664/60000]\n",
      "loss: 0.605308  [32064/60000]\n",
      "loss: 0.650509  [38464/60000]\n",
      "loss: 0.686407  [44864/60000]\n",
      "loss: 0.674155  [51264/60000]\n",
      "loss: 0.609326  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.607809 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.539398  [   64/60000]\n",
      "loss: 0.648551  [ 6464/60000]\n",
      "loss: 0.427174  [12864/60000]\n",
      "loss: 0.688158  [19264/60000]\n",
      "loss: 0.605245  [25664/60000]\n",
      "loss: 0.599157  [32064/60000]\n",
      "loss: 0.638547  [38464/60000]\n",
      "loss: 0.682365  [44864/60000]\n",
      "loss: 0.668854  [51264/60000]\n",
      "loss: 0.599395  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.598859 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.527912  [   64/60000]\n",
      "loss: 0.636918  [ 6464/60000]\n",
      "loss: 0.418244  [12864/60000]\n",
      "loss: 0.680019  [19264/60000]\n",
      "loss: 0.598365  [25664/60000]\n",
      "loss: 0.593529  [32064/60000]\n",
      "loss: 0.627470  [38464/60000]\n",
      "loss: 0.679151  [44864/60000]\n",
      "loss: 0.664385  [51264/60000]\n",
      "loss: 0.589968  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.590598 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.517221  [   64/60000]\n",
      "loss: 0.626205  [ 6464/60000]\n",
      "loss: 0.409952  [12864/60000]\n",
      "loss: 0.672351  [19264/60000]\n",
      "loss: 0.591780  [25664/60000]\n",
      "loss: 0.588258  [32064/60000]\n",
      "loss: 0.617236  [38464/60000]\n",
      "loss: 0.676624  [44864/60000]\n",
      "loss: 0.660537  [51264/60000]\n",
      "loss: 0.580956  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.582960 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.507248  [   64/60000]\n",
      "loss: 0.616302  [ 6464/60000]\n",
      "loss: 0.402248  [12864/60000]\n",
      "loss: 0.665072  [19264/60000]\n",
      "loss: 0.585424  [25664/60000]\n",
      "loss: 0.583252  [32064/60000]\n",
      "loss: 0.607767  [38464/60000]\n",
      "loss: 0.674740  [44864/60000]\n",
      "loss: 0.657235  [51264/60000]\n",
      "loss: 0.572235  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.575881 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.497890  [   64/60000]\n",
      "loss: 0.607154  [ 6464/60000]\n",
      "loss: 0.395096  [12864/60000]\n",
      "loss: 0.658112  [19264/60000]\n",
      "loss: 0.579218  [25664/60000]\n",
      "loss: 0.578414  [32064/60000]\n",
      "loss: 0.599002  [38464/60000]\n",
      "loss: 0.673409  [44864/60000]\n",
      "loss: 0.654439  [51264/60000]\n",
      "loss: 0.563834  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.569305 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.489101  [   64/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.598659  [ 6464/60000]\n",
      "loss: 0.388412  [12864/60000]\n",
      "loss: 0.651446  [19264/60000]\n",
      "loss: 0.573220  [25664/60000]\n",
      "loss: 0.573699  [32064/60000]\n",
      "loss: 0.590868  [38464/60000]\n",
      "loss: 0.672627  [44864/60000]\n",
      "loss: 0.651980  [51264/60000]\n",
      "loss: 0.555696  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.563186 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.480785  [   64/60000]\n",
      "loss: 0.590796  [ 6464/60000]\n",
      "loss: 0.382185  [12864/60000]\n",
      "loss: 0.645092  [19264/60000]\n",
      "loss: 0.567306  [25664/60000]\n",
      "loss: 0.568983  [32064/60000]\n",
      "loss: 0.583358  [38464/60000]\n",
      "loss: 0.672208  [44864/60000]\n",
      "loss: 0.649793  [51264/60000]\n",
      "loss: 0.547827  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.557476 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.472881  [   64/60000]\n",
      "loss: 0.583485  [ 6464/60000]\n",
      "loss: 0.376348  [12864/60000]\n",
      "loss: 0.638999  [19264/60000]\n",
      "loss: 0.561471  [25664/60000]\n",
      "loss: 0.564292  [32064/60000]\n",
      "loss: 0.576334  [38464/60000]\n",
      "loss: 0.672155  [44864/60000]\n",
      "loss: 0.647828  [51264/60000]\n",
      "loss: 0.540269  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.552139 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.465371  [   64/60000]\n",
      "loss: 0.576665  [ 6464/60000]\n",
      "loss: 0.370854  [12864/60000]\n",
      "loss: 0.633116  [19264/60000]\n",
      "loss: 0.555632  [25664/60000]\n",
      "loss: 0.559630  [32064/60000]\n",
      "loss: 0.569801  [38464/60000]\n",
      "loss: 0.672396  [44864/60000]\n",
      "loss: 0.645988  [51264/60000]\n",
      "loss: 0.532892  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.547138 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.458140  [   64/60000]\n",
      "loss: 0.570353  [ 6464/60000]\n",
      "loss: 0.365694  [12864/60000]\n",
      "loss: 0.627387  [19264/60000]\n",
      "loss: 0.549907  [25664/60000]\n",
      "loss: 0.555071  [32064/60000]\n",
      "loss: 0.563753  [38464/60000]\n",
      "loss: 0.672787  [44864/60000]\n",
      "loss: 0.644174  [51264/60000]\n",
      "loss: 0.525780  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.542456 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.451268  [   64/60000]\n",
      "loss: 0.564526  [ 6464/60000]\n",
      "loss: 0.360822  [12864/60000]\n",
      "loss: 0.621918  [19264/60000]\n",
      "loss: 0.544230  [25664/60000]\n",
      "loss: 0.550615  [32064/60000]\n",
      "loss: 0.558084  [38464/60000]\n",
      "loss: 0.673313  [44864/60000]\n",
      "loss: 0.642496  [51264/60000]\n",
      "loss: 0.518961  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.538075 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.444648  [   64/60000]\n",
      "loss: 0.559096  [ 6464/60000]\n",
      "loss: 0.356218  [12864/60000]\n",
      "loss: 0.616632  [19264/60000]\n",
      "loss: 0.538693  [25664/60000]\n",
      "loss: 0.546150  [32064/60000]\n",
      "loss: 0.552754  [38464/60000]\n",
      "loss: 0.673874  [44864/60000]\n",
      "loss: 0.640927  [51264/60000]\n",
      "loss: 0.512372  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.533957 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.438344  [   64/60000]\n",
      "loss: 0.554024  [ 6464/60000]\n",
      "loss: 0.351883  [12864/60000]\n",
      "loss: 0.611521  [19264/60000]\n",
      "loss: 0.533220  [25664/60000]\n",
      "loss: 0.541732  [32064/60000]\n",
      "loss: 0.547744  [38464/60000]\n",
      "loss: 0.674460  [44864/60000]\n",
      "loss: 0.639368  [51264/60000]\n",
      "loss: 0.506034  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.530080 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.432313  [   64/60000]\n",
      "loss: 0.549275  [ 6464/60000]\n",
      "loss: 0.347777  [12864/60000]\n",
      "loss: 0.606544  [19264/60000]\n",
      "loss: 0.527849  [25664/60000]\n",
      "loss: 0.537295  [32064/60000]\n",
      "loss: 0.543028  [38464/60000]\n",
      "loss: 0.675072  [44864/60000]\n",
      "loss: 0.637819  [51264/60000]\n",
      "loss: 0.499926  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.526425 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.426502  [   64/60000]\n",
      "loss: 0.544873  [ 6464/60000]\n",
      "loss: 0.343889  [12864/60000]\n",
      "loss: 0.601751  [19264/60000]\n",
      "loss: 0.522626  [25664/60000]\n",
      "loss: 0.532901  [32064/60000]\n",
      "loss: 0.538563  [38464/60000]\n",
      "loss: 0.675592  [44864/60000]\n",
      "loss: 0.636315  [51264/60000]\n",
      "loss: 0.494121  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.522977 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.420946  [   64/60000]\n",
      "loss: 0.540796  [ 6464/60000]\n",
      "loss: 0.340232  [12864/60000]\n",
      "loss: 0.597129  [19264/60000]\n",
      "loss: 0.517470  [25664/60000]\n",
      "loss: 0.528567  [32064/60000]\n",
      "loss: 0.534316  [38464/60000]\n",
      "loss: 0.676037  [44864/60000]\n",
      "loss: 0.634826  [51264/60000]\n",
      "loss: 0.488584  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.519713 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.415552  [   64/60000]\n",
      "loss: 0.536962  [ 6464/60000]\n",
      "loss: 0.336799  [12864/60000]\n",
      "loss: 0.592702  [19264/60000]\n",
      "loss: 0.512413  [25664/60000]\n",
      "loss: 0.524329  [32064/60000]\n",
      "loss: 0.530286  [38464/60000]\n",
      "loss: 0.676395  [44864/60000]\n",
      "loss: 0.633263  [51264/60000]\n",
      "loss: 0.483282  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.516618 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.410349  [   64/60000]\n",
      "loss: 0.533352  [ 6464/60000]\n",
      "loss: 0.333537  [12864/60000]\n",
      "loss: 0.588436  [19264/60000]\n",
      "loss: 0.507528  [25664/60000]\n",
      "loss: 0.520168  [32064/60000]\n",
      "loss: 0.526423  [38464/60000]\n",
      "loss: 0.676605  [44864/60000]\n",
      "loss: 0.631670  [51264/60000]\n",
      "loss: 0.478223  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.513683 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.405309  [   64/60000]\n",
      "loss: 0.529965  [ 6464/60000]\n",
      "loss: 0.330463  [12864/60000]\n",
      "loss: 0.584280  [19264/60000]\n",
      "loss: 0.502759  [25664/60000]\n",
      "loss: 0.516099  [32064/60000]\n",
      "loss: 0.522728  [38464/60000]\n",
      "loss: 0.676682  [44864/60000]\n",
      "loss: 0.630093  [51264/60000]\n",
      "loss: 0.473403  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.510894 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.400468  [   64/60000]\n",
      "loss: 0.526793  [ 6464/60000]\n",
      "loss: 0.327560  [12864/60000]\n",
      "loss: 0.580250  [19264/60000]\n",
      "loss: 0.498156  [25664/60000]\n",
      "loss: 0.512112  [32064/60000]\n",
      "loss: 0.519196  [38464/60000]\n",
      "loss: 0.676575  [44864/60000]\n",
      "loss: 0.628529  [51264/60000]\n",
      "loss: 0.468846  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.508240 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.395764  [   64/60000]\n",
      "loss: 0.523840  [ 6464/60000]\n",
      "loss: 0.324773  [12864/60000]\n",
      "loss: 0.576322  [19264/60000]\n",
      "loss: 0.493666  [25664/60000]\n",
      "loss: 0.508191  [32064/60000]\n",
      "loss: 0.515745  [38464/60000]\n",
      "loss: 0.676228  [44864/60000]\n",
      "loss: 0.626895  [51264/60000]\n",
      "loss: 0.464496  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.505712 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.391245  [   64/60000]\n",
      "loss: 0.521038  [ 6464/60000]\n",
      "loss: 0.322104  [12864/60000]\n",
      "loss: 0.572534  [19264/60000]\n",
      "loss: 0.489259  [25664/60000]\n",
      "loss: 0.504432  [32064/60000]\n",
      "loss: 0.512379  [38464/60000]\n",
      "loss: 0.675749  [44864/60000]\n",
      "loss: 0.625209  [51264/60000]\n",
      "loss: 0.460353  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.503300 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.386827  [   64/60000]\n",
      "loss: 0.518365  [ 6464/60000]\n",
      "loss: 0.319583  [12864/60000]\n",
      "loss: 0.568836  [19264/60000]\n",
      "loss: 0.485017  [25664/60000]\n",
      "loss: 0.500797  [32064/60000]\n",
      "loss: 0.509163  [38464/60000]\n",
      "loss: 0.675131  [44864/60000]\n",
      "loss: 0.623517  [51264/60000]\n",
      "loss: 0.456375  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.500995 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.382498  [   64/60000]\n",
      "loss: 0.515791  [ 6464/60000]\n",
      "loss: 0.317162  [12864/60000]\n",
      "loss: 0.565242  [19264/60000]\n",
      "loss: 0.480947  [25664/60000]\n",
      "loss: 0.497307  [32064/60000]\n",
      "loss: 0.506047  [38464/60000]\n",
      "loss: 0.674356  [44864/60000]\n",
      "loss: 0.621722  [51264/60000]\n",
      "loss: 0.452667  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.498781 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.378316  [   64/60000]\n",
      "loss: 0.513297  [ 6464/60000]\n",
      "loss: 0.314891  [12864/60000]\n",
      "loss: 0.561778  [19264/60000]\n",
      "loss: 0.477011  [25664/60000]\n",
      "loss: 0.493903  [32064/60000]\n",
      "loss: 0.503051  [38464/60000]\n",
      "loss: 0.673430  [44864/60000]\n",
      "loss: 0.619908  [51264/60000]\n",
      "loss: 0.449160  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.496663 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.374191  [   64/60000]\n",
      "loss: 0.510938  [ 6464/60000]\n",
      "loss: 0.312688  [12864/60000]\n",
      "loss: 0.558446  [19264/60000]\n",
      "loss: 0.473115  [25664/60000]\n",
      "loss: 0.490585  [32064/60000]\n",
      "loss: 0.500177  [38464/60000]\n",
      "loss: 0.672422  [44864/60000]\n",
      "loss: 0.617986  [51264/60000]\n",
      "loss: 0.445836  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.494625 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.370166  [   64/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.508674  [ 6464/60000]\n",
      "loss: 0.310585  [12864/60000]\n",
      "loss: 0.555231  [19264/60000]\n",
      "loss: 0.469361  [25664/60000]\n",
      "loss: 0.487378  [32064/60000]\n",
      "loss: 0.497464  [38464/60000]\n",
      "loss: 0.671297  [44864/60000]\n",
      "loss: 0.616021  [51264/60000]\n",
      "loss: 0.442681  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.492659 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.366287  [   64/60000]\n",
      "loss: 0.506493  [ 6464/60000]\n",
      "loss: 0.308534  [12864/60000]\n",
      "loss: 0.552069  [19264/60000]\n",
      "loss: 0.465726  [25664/60000]\n",
      "loss: 0.484294  [32064/60000]\n",
      "loss: 0.494825  [38464/60000]\n",
      "loss: 0.669999  [44864/60000]\n",
      "loss: 0.613980  [51264/60000]\n",
      "loss: 0.439761  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.490754 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.362502  [   64/60000]\n",
      "loss: 0.504347  [ 6464/60000]\n",
      "loss: 0.306534  [12864/60000]\n",
      "loss: 0.549034  [19264/60000]\n",
      "loss: 0.462116  [25664/60000]\n",
      "loss: 0.481224  [32064/60000]\n",
      "loss: 0.492265  [38464/60000]\n",
      "loss: 0.668538  [44864/60000]\n",
      "loss: 0.611979  [51264/60000]\n",
      "loss: 0.437036  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.488919 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.358855  [   64/60000]\n",
      "loss: 0.502252  [ 6464/60000]\n",
      "loss: 0.304542  [12864/60000]\n",
      "loss: 0.546090  [19264/60000]\n",
      "loss: 0.458658  [25664/60000]\n",
      "loss: 0.478283  [32064/60000]\n",
      "loss: 0.489773  [38464/60000]\n",
      "loss: 0.667020  [44864/60000]\n",
      "loss: 0.609947  [51264/60000]\n",
      "loss: 0.434570  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.487137 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.355349  [   64/60000]\n",
      "loss: 0.500180  [ 6464/60000]\n",
      "loss: 0.302681  [12864/60000]\n",
      "loss: 0.543275  [19264/60000]\n",
      "loss: 0.455304  [25664/60000]\n",
      "loss: 0.475427  [32064/60000]\n",
      "loss: 0.487393  [38464/60000]\n",
      "loss: 0.665477  [44864/60000]\n",
      "loss: 0.607928  [51264/60000]\n",
      "loss: 0.432375  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.485414 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.352019  [   64/60000]\n",
      "loss: 0.498168  [ 6464/60000]\n",
      "loss: 0.300895  [12864/60000]\n",
      "loss: 0.540568  [19264/60000]\n",
      "loss: 0.452116  [25664/60000]\n",
      "loss: 0.472586  [32064/60000]\n",
      "loss: 0.485037  [38464/60000]\n",
      "loss: 0.663893  [44864/60000]\n",
      "loss: 0.605932  [51264/60000]\n",
      "loss: 0.430176  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.483748 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.348789  [   64/60000]\n",
      "loss: 0.496214  [ 6464/60000]\n",
      "loss: 0.299197  [12864/60000]\n",
      "loss: 0.538023  [19264/60000]\n",
      "loss: 0.449178  [25664/60000]\n",
      "loss: 0.469804  [32064/60000]\n",
      "loss: 0.482790  [38464/60000]\n",
      "loss: 0.662313  [44864/60000]\n",
      "loss: 0.604058  [51264/60000]\n",
      "loss: 0.427990  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.482125 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.345608  [   64/60000]\n",
      "loss: 0.494221  [ 6464/60000]\n",
      "loss: 0.297591  [12864/60000]\n",
      "loss: 0.535495  [19264/60000]\n",
      "loss: 0.446226  [25664/60000]\n",
      "loss: 0.467228  [32064/60000]\n",
      "loss: 0.480441  [38464/60000]\n",
      "loss: 0.660748  [44864/60000]\n",
      "loss: 0.602369  [51264/60000]\n",
      "loss: 0.425826  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.480561 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce58a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278375d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac8d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
